{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766c4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ES â†’ Sharetribe uploader (Integration API)\n",
    "\n",
    "This notebook lets you select products from your serverless Elasticsearch cluster and upload them as listings to your Sharetribe marketplace using the Integration API.\n",
    "\n",
    "- Loads credentials from your `.env` (Sharetribe) and from the existing scraper config (Elasticsearch/OpenAI)\n",
    "- Inspects current Sharetribe listing structure for reference\n",
    "- Lets you search products in ES, preview and confirm before transfer\n",
    "- Minimizes OpenAI calls (only fills missing/essential texts)\n",
    "- Uploads images to Sharetribe, creates draft listings and publishes them\n",
    "- Includes an end-to-end test with one Roborock product\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02187b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install python-dotenv elasticsearch openai requests tqdm tenacity\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from elasticsearch import Elasticsearch\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
    "logger = logging.getLogger(\"es2sharetribe\")\n",
    "\n",
    "# Load env\n",
    "load_dotenv(dotenv_path=os.path.join(os.getcwd(), \".env\"))\n",
    "\n",
    "# Sharetribe credentials from .env (generated by scripts/config.js)\n",
    "SHARETRIBE_CLIENT_ID = os.getenv(\"REACT_APP_SHARETRIBE_SDK_CLIENT_ID\")\n",
    "SHARETRIBE_CLIENT_SECRET = os.getenv(\"SHARETRIBE_SDK_CLIENT_SECRET\")\n",
    "SHARETRIBE_AUTH_BASE_URL = os.getenv(\"SHARETRIBE_AUTH_BASE_URL\", \"https://flex-api.sharetribe.com\")\n",
    "SHARETRIBE_INTEG_BASE_URL = os.getenv(\"SHARETRIBE_INTEG_BASE_URL\", \"https://flex-integ-api.sharetribe.com\")\n",
    "\n",
    "if not (SHARETRIBE_CLIENT_ID and SHARETRIBE_CLIENT_SECRET):\n",
    "    logger.warning(\"Sharetribe credentials not found in .env. Please run yarn run config or set env vars.\")\n",
    "\n",
    "# Reuse OpenAI/ES config from scraper v1.ipynb conventions\n",
    "# (OpenAI uses env OPENAI_API_KEY; ES host/api_key embedded in that notebook code)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI() if OPENAI_API_KEY else None\n",
    "\n",
    "# You may adapt these from your scraper notebook if needed\n",
    "ES_HOST = os.getenv(\"ES_HOST\", \"https://my-elasticsearch-project-caece8.es.us-east-1.aws.elastic.cloud:443\")\n",
    "ES_API_KEY = os.getenv(\"ES_API_KEY\", \"X1JBeVpKY0I2VFdpQ3RTRlpTZjk6TDd5aDNkYlJELTdsRDJjTWNFVldJUQ==\")\n",
    "\n",
    "es = Elasticsearch(ES_HOST, api_key=ES_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2523648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from typing import TypedDict\n",
    "\n",
    "class STAuth(TypedDict):\n",
    "    access_token: str\n",
    "    token_type: str\n",
    "\n",
    "class ListingInput(TypedDict, total=False):\n",
    "    title: str\n",
    "    description: str\n",
    "    geolocation: dict\n",
    "    price: dict\n",
    "    publicData: dict\n",
    "    privateData: dict\n",
    "    images: List[str]\n",
    "\n",
    "SESSION: Dict[str, Any] = {}\n",
    "\n",
    "\n",
    "def get_integration_token() -> STAuth:\n",
    "    \"\"\"Client credentials OAuth for Sharetribe Flex Integration API.\"\"\"\n",
    "    url = f\"{SHARETRIBE_AUTH_BASE_URL}/v1/auth/token\"\n",
    "    payload = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": SHARETRIBE_CLIENT_ID,\n",
    "        \"client_secret\": SHARETRIBE_CLIENT_SECRET,\n",
    "        \"scope\": \"integration\",  # Access Integration API endpoints\n",
    "    }\n",
    "    resp = requests.post(url, data=payload, timeout=20)\n",
    "    try:\n",
    "        resp.raise_for_status()\n",
    "    except Exception:\n",
    "        logger.error(\"Auth failed %s: %s\", resp.status_code, resp.text)\n",
    "        raise\n",
    "    data = resp.json()\n",
    "    auth = STAuth(access_token=data.get(\"access_token\"), token_type=data.get(\"token_type\", \"Bearer\"))\n",
    "    SESSION[\"st_auth\"] = auth\n",
    "    return auth\n",
    "\n",
    "\n",
    "def st_headers() -> Dict[str, str]:\n",
    "    auth = SESSION.get(\"st_auth\") or get_integration_token()\n",
    "    return {\"Authorization\": f\"Bearer {auth['access_token']}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "\n",
    "def get_existing_listings(limit: int = 10) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Inspect current listings to learn structure (for mapping).\"\"\"\n",
    "    url = f\"{SHARETRIBE_INTEG_BASE_URL}/v1/integration_api/listings\"\n",
    "    params = {\"per_page\": limit}\n",
    "    r = requests.get(url, headers=st_headers(), params=params, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    return r.json().get(\"data\", [])\n",
    "\n",
    "\n",
    "def create_draft_listing(payload: ListingInput) -> Dict[str, Any]:\n",
    "    url = f\"{SHARETRIBE_INTEG_BASE_URL}/v1/integration_api/listings\"\n",
    "    r = requests.post(url, headers=st_headers(), json=payload, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def upload_image_to_listing(listing_id: str, image_url: str) -> Dict[str, Any]:\n",
    "    \"\"\"Upload remote image by URL to a listing (Integration API supports multipart uploads).\"\"\"\n",
    "    # Download first to bytes\n",
    "    img_resp = requests.get(image_url, timeout=30)\n",
    "    img_resp.raise_for_status()\n",
    "\n",
    "    files = {\"image\": (\"image.jpg\", img_resp.content, \"image/jpeg\")}\n",
    "    url = f\"{SHARETRIBE_INTEG_BASE_URL}/v1/integration_api/listings/{listing_id}/images\"\n",
    "    r = requests.post(url, headers={\"Authorization\": st_headers()[\"Authorization\"]}, files=files, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def publish_listing(listing_id: str) -> Dict[str, Any]:\n",
    "    url = f\"{SHARETRIBE_INTEG_BASE_URL}/v1/integration_api/listings/{listing_id}/publish\"\n",
    "    r = requests.post(url, headers=st_headers(), timeout=20)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1403b0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_search(query: Dict[str, Any], index: str = \"inventory_vector\") -> List[Dict[str, Any]]:\n",
    "    res = es.search(index=index, body=query)\n",
    "    return res.get(\"hits\", {}).get(\"hits\", [])\n",
    "\n",
    "\n",
    "def sample_es_schema(query_brand: str = \"roborock\") -> List[Dict[str, Any]]:\n",
    "    q = {\n",
    "        \"query\": {\n",
    "            \"match\": {\"brand\": query_brand}\n",
    "        },\n",
    "        \"size\": 5\n",
    "    }\n",
    "    hits = es_search(q)\n",
    "    logger.info(\"Sample ES docs for brand=%s: %s\", query_brand, len(hits))\n",
    "    return hits\n",
    "\n",
    "\n",
    "# Show a quick peek at existing Sharetribe data structure\n",
    "existing = get_existing_listings(limit=3)\n",
    "logger.info(\"Fetched %d existing listings from Sharetribe for reference\", len(existing))\n",
    "existing[:1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94e2833",
   "metadata": {},
   "source": [
    "def es_search(query: Dict[str, Any], index: str = \"inventory_vector\") -> List[Dict[str, Any]]:\n",
    "    res = es.search(index=index, body=query)\n",
    "    return res.get(\"hits\", {}).get(\"hits\", [])\n",
    "\n",
    "\n",
    "def sample_es_schema(query_brand: str = \"roborock\") -> List[Dict[str, Any]]:\n",
    "    q = {\n",
    "        \"query\": {\n",
    "            \"match\": {\"brand\": query_brand}\n",
    "        },\n",
    "        \"size\": 5\n",
    "    }\n",
    "    hits = es_search(q)\n",
    "    logger.info(\"Sample ES docs for brand=%s: %s\", query_brand, len(hits))\n",
    "    return hits\n",
    "\n",
    "\n",
    "# Show a quick peek at existing Sharetribe data structure\n",
    "existing = get_existing_listings(limit=3)\n",
    "logger.info(\"Fetched %d existing listings from Sharetribe for reference\", len(existing))\n",
    "existing[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed10af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sharetribe_payload_from_es(es_doc: Dict[str, Any]) -> ListingInput:\n",
    "    src = es_doc.get('_source', {})\n",
    "    title = src.get('product_name') or src.get('name') or \"Untitled\"\n",
    "    description = src.get('product_description') or src.get('extended_description')\n",
    "\n",
    "    # Minimize OpenAI calls: only if description missing/too short\n",
    "    if (not description or len(description) < 50) and openai_client and src.get('raw_html'):\n",
    "        try:\n",
    "            prompt = f\"\"\"\n",
    "You will write a concise, technical product description (max 500 chars) for a marketplace listing based on this content:\n",
    "{src.get('raw_html')[:7000]}\n",
    "Ensure no brand repetition if the title already contains it; avoid marketing fluff.\n",
    "\"\"\"\n",
    "            resp = openai_client.chat.completions.create(\n",
    "                model=\"gpt-4.1-mini\",\n",
    "                messages=[{\"role\":\"system\",\"content\":\"You write compact, technical marketplace descriptions.\"},{\"role\":\"user\",\"content\":prompt}],\n",
    "                temperature=0.2\n",
    "            )\n",
    "            description = resp.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            logger.warning(\"OpenAI description fallback failed: %s\", e)\n",
    "            description = description or \"\"\n",
    "\n",
    "    price = src.get('price') or {\"amount\": 0, \"currency\": \"USD\"}\n",
    "    # Sharetribe expects price in subunits (e.g. cents)\n",
    "    if isinstance(price, dict) and 'amount' in price:\n",
    "        amount = price['amount']\n",
    "        if amount and amount < 1000:  # if likely dollars, convert to cents\n",
    "            amount = int(round(float(amount) * 100))\n",
    "        price = {\"amount\": int(amount or 0), \"currency\": price.get('currency', 'USD')}\n",
    "    else:\n",
    "        price = {\"amount\": 0, \"currency\": \"USD\"}\n",
    "\n",
    "    public_data = {\n",
    "        \"brand\": src.get(\"brand\"),\n",
    "        \"product_types\": src.get(\"product_types\"),\n",
    "        \"connectivity\": src.get(\"connectivity\"),\n",
    "        \"amazon_url\": src.get(\"amazon_url\"),\n",
    "        \"vendor_product_id\": src.get(\"vendor_product_id\"),\n",
    "        \"tech_specs\": src.get(\"tech_specs\"),\n",
    "    }\n",
    "\n",
    "    payload: ListingInput = {\n",
    "        \"title\": title[:70],\n",
    "        \"description\": description[:5000] if description else \"\",\n",
    "        \"price\": price,\n",
    "        \"publicData\": {k: v for k, v in public_data.items() if v is not None},\n",
    "        # Optional: place in a generic location or omit\n",
    "    }\n",
    "    return payload\n",
    "\n",
    "\n",
    "def extract_primary_image(es_doc: Dict[str, Any]) -> Optional[str]:\n",
    "    src = es_doc.get('_source', {})\n",
    "    if src.get('image_url'):\n",
    "        return src['image_url']\n",
    "    rel = src.get('related_images') or []\n",
    "    for img in rel:\n",
    "        if isinstance(img, dict) and img.get('source_link'):\n",
    "            return img['source_link']\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1744342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def interactive_select_from_es(default_brand: str = \"roborock\") -> List[Dict[str, Any]]:\n",
    "    print(\"Enter an Elasticsearch simple query (brand, keywords, etc.). Leave blank to use default.\")\n",
    "    try:\n",
    "        user_brand = input(f\"Brand (default {default_brand}): \").strip() or default_brand\n",
    "    except Exception:\n",
    "        user_brand = default_brand\n",
    "\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\"brand\": user_brand}\n",
    "        },\n",
    "        \"size\": 50\n",
    "    }\n",
    "    hits = es_search(query)\n",
    "    rows = []\n",
    "    for h in hits:\n",
    "        s = h.get('_source', {})\n",
    "        rows.append({\n",
    "            \"_id\": h.get('_id'),\n",
    "            \"brand\": s.get('brand'),\n",
    "            \"product_name\": s.get('product_name'),\n",
    "            \"product_types\": s.get('product_types'),\n",
    "            \"has_image\": 1 if (s.get('image_url') or s.get('related_images')) else 0,\n",
    "            \"amazon_url\": s.get('amazon_url'),\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        display(df)\n",
    "    else:\n",
    "        print(\"No results.\")\n",
    "\n",
    "    print(\"Enter comma-separated row numbers to transfer (e.g. 0,2,3). Leave blank to cancel.\")\n",
    "    try:\n",
    "        sel = input(\"Selection: \").strip()\n",
    "    except Exception:\n",
    "        sel = \"\"\n",
    "    if not sel:\n",
    "        return []\n",
    "\n",
    "    idxs = []\n",
    "    for part in sel.split(','):\n",
    "        part = part.strip()\n",
    "        if part.isdigit():\n",
    "            idxs.append(int(part))\n",
    "    selected = [hits[i] for i in idxs if 0 <= i < len(hits)]\n",
    "\n",
    "    print(f\"You selected {len(selected)} items. Confirm transfer? [y/N]\")\n",
    "    try:\n",
    "        confirm = input(\"\").strip().lower()\n",
    "    except Exception:\n",
    "        confirm = \"n\"\n",
    "    if confirm != 'y':\n",
    "        return []\n",
    "    return selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8d7616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_one_es_doc(es_doc: Dict[str, Any]) -> Optional[str]:\n",
    "    src = es_doc.get('_source', {})\n",
    "    payload = build_sharetribe_payload_from_es(es_doc)\n",
    "    logger.info(\"Creating draft listing: %s\", payload.get('title'))\n",
    "    draft = create_draft_listing(payload)\n",
    "    listing_id = draft.get('data', {}).get('id')\n",
    "\n",
    "    # Upload image(s)\n",
    "    img_url = extract_primary_image(es_doc)\n",
    "    if img_url and listing_id:\n",
    "        try:\n",
    "            logger.info(\"Uploading primary image for %s\", listing_id)\n",
    "            upload_image_to_listing(listing_id, img_url)\n",
    "        except Exception as e:\n",
    "            logger.warning(\"Image upload failed for %s: %s\", listing_id, e)\n",
    "\n",
    "    # Publish\n",
    "    if listing_id:\n",
    "        try:\n",
    "            logger.info(\"Publishing %s\", listing_id)\n",
    "            publish_listing(listing_id)\n",
    "            return listing_id\n",
    "        except Exception as e:\n",
    "            logger.error(\"Publish failed for %s: %s\", listing_id, e)\n",
    "            return listing_id\n",
    "    return None\n",
    "\n",
    "\n",
    "def transfer_interactive():\n",
    "    selected = interactive_select_from_es(default_brand=\"roborock\")\n",
    "    if not selected:\n",
    "        print(\"No transfer executed.\")\n",
    "        return []\n",
    "    created_ids = []\n",
    "    for doc in tqdm(selected, desc=\"Transferring\"):\n",
    "        try:\n",
    "            lid = transfer_one_es_doc(doc)\n",
    "            if lid:\n",
    "                created_ids.append(lid)\n",
    "        except Exception as e:\n",
    "            logger.exception(\"Transfer failed: %s\", e)\n",
    "    print(f\"Done. Created/updated {len(created_ids)} listings.\")\n",
    "    return created_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d837e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Roborock end-to-end smoke test (single item)\n",
    "q = {\n",
    "    \"query\": {\"match\": {\"brand\": \"Roborock\"}},\n",
    "    \"size\": 1\n",
    "}\n",
    "robo = es_search(q)\n",
    "if robo:\n",
    "    print(\"Testing with:\", robo[0].get('_source', {}).get('product_name'))\n",
    "    _ = transfer_one_es_doc(robo[0])\n",
    "else:\n",
    "    print(\"No Roborock product found in ES.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f9df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the interactive transfer\n",
    "# created_ids = transfer_interactive()\n",
    "# created_ids\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
